# FinewebEduScorer

## Overview

The **FineWeb-Edu Scorer** is a model-based evaluation tool designed to assess the **educational value** of text data. Originally developed to filter and curate educational content from web datasets, this classifier was trained on 450,000 annotations generated by LLama3-70B-Instruct for web samples from the FineWeb dataset. It provides a regression-based score indicating how educationally valuable a given text is, ranging from non-educational content to highly educational material suitable for learning purposes.

## Metric Definition:

* **Definition:** 

  A regression score ranging from 0 to 5 that quantifies the educational value of text content.

* **Explanation:** 

  The educational score estimates how suitable and valuable the content is for educational purposes, particularly for primary and grade school levels.
  
  * **Score 0-1:** Content has minimal to no educational value; may be commercial, entertainment-focused, or lacks substantive learning content.
  * **Score 2-3:** Content has moderate educational value with some informative elements but may lack depth or clarity.
  * **Score 4-5:** Content demonstrates high educational value with clear explanations, well-structured information, and strong pedagogical qualities.

* **Note:** 

  The model outputs continuous scores, but they are often rounded to integer values (0-5) for practical data curation. A threshold of `int_score >= 3` is commonly recommended for filtering educational content.

## YAML Configuration

```yaml
name: FinewebEduScorer
model: HuggingFaceFW/fineweb-edu-classifier
max_length: 2048
batch_size: 32
```

### Configuration Parameters

| Parameter | Type | Default | Description |
|-----------|------|---------|-------------|
| `name` | string | `"FinewebEduScorer"` | Identifier for the scorer |
| `model` | string | `"HuggingFaceFW/fineweb-edu-classifier"` | Path to the model checkpoint or Hugging Face model identifier. Can specify a local model path if you have a fine-tuned version |
| `max_length` | integer | `2048` | Maximum sequence length for tokenization (valid range: 1-2048 tokens) |
| `batch_size` | integer | `32` | Number of samples to process in each batch. Adjust based on available GPU memory |

## Underlying Model

The scorer uses [HuggingFaceFW/fineweb-edu-classifier](https://huggingface.co/HuggingFaceFW/fineweb-edu-classifier), a regression model built upon the **Snowflake-arctic-embed** architecture with an added classification head for single regression output.

### Model Training Details

* **Base Architecture:** Snowflake-arctic-embed with a regression classification head
* **Training Data:** 450,000 web samples annotated by LLama3-70B-Instruct
* **Training Configuration:**
  * 20 epochs with learning rate 3e-4
  * Embedding and encoder layers frozen during training
  * Focus on training the classification head only
* **Performance:** Achieves 82% F1 score when converted to a binary classifier (threshold = 3)

The model was specifically trained to replicate the educational quality judgments of LLama3-70B-Instruct, making it a lightweight and efficient alternative for large-scale data filtering.

## Scoring Process

1. **Text Extraction:** For each data item, the scorer extracts and concatenates:
   - `instruction`: The task description or question
   - `input`: Additional context (if present)
   - `output`: The response or answer
   
   These fields are joined with newlines to form a complete text sample.

2. **Tokenization:** Texts are batch-tokenized using the model's tokenizer with:
   - Padding to the longest sequence in the batch
   - Truncation at `max_length` tokens
   - Conversion to PyTorch tensors

3. **Inference:** The model processes the tokenized inputs and outputs logits from the regression head. The logits are converted to float scores representing the educational value.

4. **Score Extraction:** Raw regression scores are returned as floating-point values. These can be:
   - Used directly as continuous scores for ranking
   - Rounded to integers (0-5) for classification purposes
   - Thresholded (e.g., `int_score >= 3`) for binary filtering

5. **Batch Processing:** The scorer processes data in configurable batch sizes for efficiency, with progress tracking via tqdm progress bars.

## Output Format

For each input sample, the scorer returns:

```json
{
  "id": 1,
  "score": 3.847
}
```

- `id`: The unique identifier for the data sample, extracted from the input data's `id` field
- `score`: The continuous educational value score predicted by the model (range: 0-5, higher scores indicate greater educational value)

## Citation

```bibtex
@article{penedo2024fineweb,
  title={The fineweb datasets: Decanting the web for the finest text data at scale},
  author={Penedo, Guilherme and Kydl{\'\i}{\v{c}}ek, Hynek and Lozhkov, Anton and Mitchell, Margaret and Raffel, Colin A and Von Werra, Leandro and Wolf, Thomas and others},
  journal={Advances in Neural Information Processing Systems},
  volume={37},
  pages={30811--30849},
  year={2024}
}
```

